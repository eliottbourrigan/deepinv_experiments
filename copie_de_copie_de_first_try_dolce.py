# -*- coding: utf-8 -*-
"""Copie de Copie de first_try_dolce.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12OpFR8Cl48YlwnSG2dUA6sD46VpzUw3H

# Implementing DOLCE algorithm

# 1. Train the conditional denoiser

## Load Data
"""

import deepinv as dinv
from torch.utils.data import DataLoader
import torch
from pathlib import Path
from torchvision import transforms, datasets
from deepinv.training_utils import train, test

"""### Setup paths for data loading and results"""

import deepinv as dinv
from torch.utils.data import DataLoader
import torch
from pathlib import Path
from torchvision import transforms, datasets
from deepinv.training_utils import train, test
from torch.utils.data import Subset

BASE_DIR = Path(".")
ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
DATA_DIR = BASE_DIR / "measurements"
RESULTS_DIR = BASE_DIR / "results"
DEG_DIR = BASE_DIR / "degradations"
CKPT_DIR = BASE_DIR / "ckpts"


# delete the measurements and results directories
import shutil

if DATA_DIR.exists():
    shutil.rmtree(DATA_DIR)
if RESULTS_DIR.exists():
    shutil.rmtree(RESULTS_DIR)

# Set the global random seed from pytorch to ensure reproducibility of the example.
torch.manual_seed(0)

device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")



operation = "denoise"
train_dataset_name = "CIFAR10"

transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(32)])

train_dataset = datasets.CIFAR10(
    root="../datasets/", train=True, transform=transform, download=True
)
test_dataset = datasets.CIFAR10(
    root="../datasets/", train=False, transform=transform, download=True
)

BASE_DIR = Path(".")
ORIGINAL_DATA_DIR = BASE_DIR / "data"
DATA_DIR = BASE_DIR
RESULTS_DIR = BASE_DIR / "results"
# DEG_DIR = BASE_DIR / "degradations"
CKPT_DIR = BASE_DIR / "ckpts"

# # delete the measurements and results directories
# import shutil

# if DATA_DIR.exists():
#     shutil.rmtree(DATA_DIR)
# if RESULTS_DIR.exists():
#     shutil.rmtree(RESULTS_DIR)

# # Set the global random seed from pytorch to ensure reproducibility of the example.
# torch.manual_seed(0)

device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

"""### Load base image datasets"""

physics = dinv.physics.Tomography(
    img_width=32,
    angles=60, #Â i don't know how to change it and if it is relevant or not
    circle=False,
    device=device,
    noise_model=dinv.physics.GaussianNoise(0.1),
)

# Use parallel dataloader if using a GPU to fasten training,
# otherwise, as all computes are on CPU, use synchronous data loading.
num_workers = 4 if torch.cuda.is_available() else 0
dataset_name = "CIFAR10"
operation = "tomography"
measurement_dir = DATA_DIR / dataset_name / operation
dinv_dataset_path = dinv.datasets.generate_dataset(
    train_dataset=train_dataset,
    test_dataset=None,
    physics=physics,
    device=device,
    save_dir=measurement_dir,
    num_workers=num_workers,
)

train_dataset = dinv.datasets.HDF5Dataset(path=dinv_dataset_path, train=True)

# display an image from the base dataset
x_train, y_train = train_dataset[0]
dinv.utils.plot([x_train.unsqueeze(0), y_train.unsqueeze(0)])

"""### Generate a dataset of measurements using tomography"""

print(test_dataset[0][0].shape)

print("Training dataset size:", len(train_dataset))
print("Test dataset size:", len(test_dataset))
print("Image size:", x_train.shape)
print("Measurement size:", y_train.shape)

"""### Create dataloader"""

batch_size = 16

train_dataloader = DataLoader(
    train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True
)

# test_dataloader = DataLoader(
#     test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False
# )

"""### Set up the denoiser model

"""

# class create from the model of Artifacts removal
import torch
import torch.nn as nn

class ConditionalDenoiser(nn.Module):
    r"""
    Conditional denoiser network

    :param torch.nn.Module backbone_net: Base network :math:`\phi`, can be pretrained or not.
    :param bool pinv: If ``True`` uses pseudo-inverse :math:`A^{\dagger}y` instead of the default transpose.
    :param torch.device device: cpu or gpu.
    """

    def __init__(self, backbone_net, pinv=False, ckpt_path=None, device=None):
        super(ConditionalDenoiser, self).__init__()
        self.pinv = pinv
        self.backbone_net = backbone_net

        if ckpt_path is not None:
            self.backbone_net.load_state_dict(torch.load(ckpt_path), strict=True)
            self.backbone_net.eval()

        if type(self.backbone_net).__name__ == "UNetRes":
            for _, v in self.backbone_net.named_parameters():
                v.requires_grad = False
            self.backbone_net = self.backbone_net.to(device)

    def forward(self, x, sigma, c, **kwargs): # put x, sigma and c into the forward
        r"""
        Reconstructs a signal estimate from measurements y using the condition

        :param torch.tensor y: measurements
        :param deepinv.physics.Physics physics: forward operator
        """
        xp = torch.cat([c, x], dim=1)

        return self.backbone_net(xp, sigma)

"""### Training loop"""

# create the model
model = ConditionalDenoiser(
    backbone_net=dinv.models.UNet(
    in_channels=6, # because of the condition
    out_channels=3
)).to(device)  # we can use different models here, for example, UNet with attention as in the paper or with residual blocks

import torchvision.utils
from deepinv.utils import (
    save_model,
    AverageMeter,
    get_timestamp,
    cal_psnr,
)
from deepinv.utils import plot, plot_curves, wandb_plot_curves, rescale_img, zeros_like
import numpy as np
from tqdm import tqdm
import torch
import wandb
from pathlib import Path


def train(
    model,
    train_dataloader,
    epochs,
    losses,
    eval_dataloader=None,
    physics=None,
    optimizer=None,
    grad_clip=None,
    scheduler=None,
    device="cpu",
    ckp_interval=1,
    eval_interval=1,
    save_path=".",
    verbose=False,
    unsupervised=False,
    plot_images=False,
    plot_metrics=False,
    wandb_vis=False,
    wandb_setup={},
    online_measurements=False,
    plot_measurements=True,
    check_grad=False,
    ckpt_pretrained=None,
    fact_losses=None,
    freq_plot=1,
):
    r"""
    Trains a reconstruction network.


    .. note::

        The losses can be chosen from :ref:`the libraries' training losses <loss>`, or can be a custom loss function,
        as long as it takes as input ``(x, x_net, y, physics, model)`` and returns a scalar, where ``x`` is the ground
        reconstruction, ``x_net`` is the network reconstruction :math:`\inversef{y, A}`,
        ``y`` is the measurement vector, ``physics`` is the forward operator
        and ``model`` is the reconstruction network. Note that not all inpus need to be used by the loss,
        e.g., self-supervised losses will not make use of ``x``.


    :param torch.nn.Module, deepinv.models.ArtifactRemoval model: Reconstruction network, which can be PnP, unrolled, artifact removal
        or any other custom reconstruction network.
    :param torch.utils.data.DataLoader train_dataloader: Train dataloader.
    :param int epochs: Number of training epochs.
    :param torch.nn.Module, list of torch.nn.Module losses: Loss or list of losses used for training the model.
    :param torch.utils.data.DataLoader eval_dataloader: Evaluation dataloader.
    :param deepinv.physics.Physics, list[deepinv.physics.Physics] physics: Forward operator(s)
        used by the reconstruction network at train time.
    :param torch.nn.optim optimizer: Torch optimizer for training the network.
    :param float grad_clip: Gradient clipping value for the optimizer. If None, no gradient clipping is performed.
    :param torch.nn.optim scheduler: Torch scheduler for changing the learning rate across iterations.
    :param torch.device device: gpu or cpu.
    :param int ckp_interval: The model is saved every ``ckp_interval`` epochs.
    :param int eval_interval: Number of epochs between each evaluation of the model on the evaluation set.
    :param str save_path: Directory in which to save the trained model.
    :param bool verbose: Output training progress information in the console.
    :param bool unsupervised: Train an unsupervised network, i.e., uses only measurement vectors y for training.
    :param bool plot_images: Plots reconstructions every ``ckp_interval`` epochs.
    :param bool wandb_vis: Use Weights & Biases visualization, see https://wandb.ai/ for more details.
    :param dict wandb_setup: Dictionary with the setup for wandb, see https://docs.wandb.ai/quickstart for more details.
    :param bool online_measurements: Generate the measurements in an online manner at each iteration by calling
         ``physics(x)``. This results in a wider range of measurements if the physics' parameters, such as
         parameters of the forward operator or noise realizations, can change between each sample; these are updated
         with the ``physics.reset()`` method. If ``online_measurements=False``, the measurements are loaded from the training dataset
    :param bool plot_measurements: Plot the measurements y. default=True.
    :param bool check_grad: Check the gradient norm at each iteration.
    :param str ckpt_pretrained: path of the pretrained checkpoint. If None, no pretrained checkpoint is loaded.
    :param list fact_losses: List of factors to multiply the losses. If None, all losses are multiplied by 1.
    :param int freq_plot: Frequency of plotting images to wandb. If 1, plots at each epoch.
    :returns: Trained model.
    """
    save_path = Path(save_path)

    # wandb initialiation
    if wandb_vis:
        if wandb.run is None:
            wandb.init(**wandb_setup)

    # set the different metrics
    meters = []
    total_loss = AverageMeter("loss", ":.2e")
    meters.append(total_loss)
    if not isinstance(losses, list) or isinstance(losses, tuple):
        losses = [losses]
    if fact_losses is None:
        fact_losses = [1] * len(losses)
    losses_verbose = [AverageMeter("Loss_" + l.name, ":.2e") for l in losses]
    for loss in losses_verbose:
        meters.append(loss)
    train_psnr = AverageMeter("Train_psnr_model", ":.2f")
    meters.append(train_psnr)
    if eval_dataloader:
        eval_psnr = AverageMeter("Eval_psnr_model", ":.2f")
        meters.append(eval_psnr)
    if check_grad:
        check_grad_val = AverageMeter("Gradient norm", ":.2e")
        meters.append(check_grad_val)

    save_path = f"{save_path}/{get_timestamp()}"

    # count the overall training parameters
    params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"The model has {params} trainable parameters")

    # make physics and data_loaders of list type
    if type(physics) is not list:
        physics = [physics]
    if type(train_dataloader) is not list:
        train_dataloader = [train_dataloader]
    if eval_dataloader and type(eval_dataloader) is not list:
        eval_dataloader = [eval_dataloader]

    G = len(train_dataloader)

    loss_history = []

    log_dict = {}

    epoch_start = 0
    if ckpt_pretrained is not None:
        checkpoint = torch.load(ckpt_pretrained)
        model.load_state_dict(checkpoint["state_dict"])
        optimizer.load_state_dict(checkpoint["optimizer"])
        epoch_start = checkpoint["epoch"]

    for epoch in range(epoch_start, epochs):
        ### Evaluation

        if wandb_vis:
            wandb_log_dict_epoch = {"epoch": epoch}

        # perform evaluation every eval_interval epoch
        perform_eval = (
            (not unsupervised)
            and eval_dataloader
            and ((epoch + 1) % eval_interval == 0 or epoch + 1 == epochs)
        )

        if perform_eval:
            test_psnr, _, _, _ = test(
                model,
                eval_dataloader,
                physics,
                device,
                verbose=False,
                plot_images=plot_images,
                plot_metrics=plot_metrics,
                wandb_vis=wandb_vis,
                wandb_setup=wandb_setup,
                step=epoch,
                online_measurements=online_measurements,
            )
            eval_psnr.update(test_psnr)
            log_dict["eval_psnr"] = test_psnr
            if wandb_vis:
                wandb_log_dict_epoch["eval_psnr"] = test_psnr

        # wandb logging
        if wandb_vis:
            last_lr = None if scheduler is None else scheduler.get_last_lr()[0]
            wandb_log_dict_epoch["learning rate"] = last_lr

            wandb.log(wandb_log_dict_epoch)

        ### Training

        model.train()

        for meter in meters:
            meter.reset()  # reset the metric at each epoch

        iterators = [iter(loader) for loader in train_dataloader]
        batches = len(train_dataloader[G - 1])

        noise_module = dinv.physics.UniformGaussianNoise()

        for i in (progress_bar := tqdm(range(batches), disable=not verbose)):
            progress_bar.set_description(f"Epoch {epoch + 1}")

            if wandb_vis:
                wandb_log_dict_iter = {}

            # random permulation of the dataloaders
            G_perm = np.random.permutation(G)

            for g in G_perm:  # for each dataloader
                if online_measurements:  # the measurements y are created on-the-fly
                    x, _ = next(
                        iterators[g]
                    )  # In this case the dataloader outputs also a class label
                    x = x.to(device)
                    physics_cur = physics[g]

                    if isinstance(physics_cur, torch.nn.DataParallel):
                        physics_cur.module.noise_model.__init__()
                    else:
                        physics_cur.reset()

                    y = physics_cur(x) #Â a check

                else:  # the measurements y were pre-computed
                    if unsupervised:
                        y = next(iterators[g])
                        x = None
                    else:
                        x, y = next(iterators[g])
                        if type(x) is list or type(x) is tuple:
                            x = [s.to(device) for s in x]
                        else:
                            x = x.to(device)

                    physics_cur = physics[g]

                y = y.to(device)

                optimizer.zero_grad()



                x_noisy = noise_module(x)


                # c = physics_cur.A_adjoint(y) if not model.pinv else physics_cur.A_dagger(y)
                c = physics_cur.A_adjoint(y)
                # run the forward model
                x_net = model(x_noisy, noise_module.sigma, c) # put xp c and sigma into the model

                # compute the losses
                loss_total = 0
                for k, l in enumerate(losses):
                    loss = l(x=x, x_net=x_net, y=y, physics=physics[g], model=model)
                    loss_total += fact_losses[k] * loss
                    losses_verbose[k].update(loss.item())
                    if len(losses) > 1:
                        log_dict["loss_" + l.name] = losses_verbose[k].avg
                        if wandb_vis:
                            wandb_log_dict_iter["loss_" + l.name] = loss.item()
                if wandb_vis:
                    wandb_log_dict_iter["training loss"] = loss_total.item()
                total_loss.update(loss_total.item())
                log_dict["total_loss"] = total_loss.avg

                # backward the total loss
                loss_total.backward()

                # gradient clipping
                if grad_clip is not None:
                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)

                if check_grad:
                    # from https://discuss.pytorch.org/t/check-the-norm-of-gradients/27961/7
                    grads = [
                        param.grad.detach().flatten()
                        for param in model.parameters()
                        if param.grad is not None
                    ]
                    norm_grads = torch.cat(grads).norm()
                    wandb_log_dict_iter["gradient norm"] = norm_grads.item()
                    check_grad_val.update(norm_grads.item())

                # optimize step
                optimizer.step()

                # training psnr and logging
                if not unsupervised:
                    with torch.no_grad():
                        psnr = cal_psnr(x_net, x)
                        train_psnr.update(psnr)
                        if wandb_vis:
                            wandb_log_dict_iter["train_psnr"] = psnr
                            wandb.log(wandb_log_dict_iter)
                        log_dict["train_psnr"] = train_psnr.avg

                progress_bar.set_postfix(log_dict)

        # wandb plotting of training images
        if wandb_vis:
            # log average training metrics
            log_dict_post_epoch = {}
            log_dict_post_epoch["mean training loss"] = total_loss.avg
            log_dict_post_epoch["mean training psnr"] = train_psnr.avg
            if check_grad:
                log_dict_post_epoch["mean gradient norm"] = check_grad_val.avg

            with torch.no_grad():
                if plot_measurements and y.shape != x.shape:
                    y_reshaped = torch.nn.functional.interpolate(y, size=x.shape[2])
                    if hasattr(physics_cur, "A_adjoint"):
                        imgs = [y_reshaped, physics_cur.A_adjoint(y), x_net, x]
                        caption = (
                            "From top to bottom: input, backprojection, output, target"
                        )
                    else:
                        imgs = [y_reshaped, x_net, x]
                        caption = "From top to bottom: input, output, target"
                else:
                    if hasattr(physics_cur, "A_adjoint"):
                        if isinstance(physics_cur, torch.nn.DataParallel):
                            back = physics_cur.module.A_adjoint(y)
                        else:
                            back = physics_cur.A_adjoint(y)
                        imgs = [back, x_net, x]
                        caption = "From top to bottom: backprojection, output, target"
                    else:
                        imgs = [x_net, x]
                        caption = "From top to bottom: output, target"

                vis_array = torch.cat(imgs, dim=0)
                for i in range(len(vis_array)):
                    vis_array[i] = rescale_img(vis_array[i], rescale_mode="min_max")
                grid_image = torchvision.utils.make_grid(vis_array, nrow=y.shape[0])
                if epoch % freq_plot == 0:
                    images = wandb.Image(
                        grid_image,
                        caption=caption,
                    )
                    log_dict_post_epoch["Training samples"] = images

        if wandb_vis:
            wandb.log(log_dict_post_epoch)

        loss_history.append(total_loss.avg)

        if scheduler:
            scheduler.step()

        # Saving the model
        save_model(
            epoch,
            model,
            optimizer,
            ckp_interval,
            epochs,
            loss_history,
            str(save_path),
            eval_psnr=eval_psnr if perform_eval else None,
        )

    if wandb_vis:
        wandb.save("model.h5")

    return model

import deepinv.loss as loss
import torch.optim as optim
#reduce de stepsize if the training continue to be instable

epochs = 1  # choose training epochs
learning_rate = 5e-4
T = 1000
# choose self-supervised training loss
loss = loss.SupLoss()

# choose optimizer and scheduler
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8) + 1)
CKPT_DIR = "training"
trained_model = train(
    model,
    train_dataloader,
    epochs,
    loss,
    eval_dataloader=None,
    physics=physics,
    optimizer=optimizer,
    grad_clip=None,
    scheduler=scheduler,
    device=device,
    ckp_interval=1,
    eval_interval=1,
    save_path=CKPT_DIR,
    verbose=True,
    unsupervised=False,
    plot_images=False,
    plot_metrics=False,
    wandb_vis=False,
    wandb_setup={},
    online_measurements=False,
    plot_measurements=True,
    check_grad=False,
    ckpt_pretrained=None,
    fact_losses=None,
    freq_plot=1,
)

import numpy as np
import torch
import matplotlib.pyplot as plt
from tqdm import tqdm
import deepinv as dinv
from deepinv.utils.plotting import plot
from deepinv.optim.data_fidelity import L2
from deepinv.utils.demo import load_url_image, get_image_url

url = "https://cdn-images.zoobeauval.com/naWDShzwEIJZuwLCd1k8uMHOOCI=/730x730/https%3A%2F%2Fs3.eu-west-3.amazonaws.com%2Fimages.zoobeauval.com%2F2020%2F06%2Fsticker-3-5ee3535a57292.jpg"

x_true = load_url_image(url=url, img_size=256, grayscale=False, device=device)

# Resize the image to 32x32
resize_transform = transforms.Compose([
    transforms.Resize((32, 32)),
])

torch.manual_seed(0)
x_true = resize_transform(x_true).to(device)
x = torch.zeros((16, 3, 32, 32)).to(device)
x_panther = x_true.clone().to(device)

#x, _ = train_dataset[-17:-1]
x = x.clone().to(device)
x = torch.randn((16, 3, 32, 32)).to(device)
x[:1, :, :, :] = x_panther


physics = dinv.physics.Tomography(
    img_width=32,
    angles=60,
    circle=False,
    device=device,
    noise_model=dinv.physics.GaussianNoise(0.2),
)

noise_module = dinv.physics.UniformGaussianNoise(sigma=0.5)
y = physics(x) #Â a check
y = y.to(device)
optimizer.zero_grad()
x_noisy = noise_module(x)
c = physics.A_adjoint(y)
# c = torch.randn((16, 3, 32, 32)).to(device)
model.eval()
x_net = model(x_noisy, noise_module.sigma, c) # put xp c and sigma into the model

plot([x, x_noisy, c, x_net, x_net - x], ["x", "x_noisy", "c (using A_)", "x_net", "error"])
for x_ in [x, x_noisy, c, x_net]:
  print(torch.max(x_).item(), torch.min(x_).item(), x_.shape)

